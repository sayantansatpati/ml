{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DATSCI W261 Week 5: JRW Notes\n",
    "##Topics: \n",
    "    > Synonyms and synonym detection\n",
    "    > Google 5-grams\n",
    "    > AWS command line interface\n",
    "    > Managing data on s3\n",
    "    > Modifying the default Hadoop sort in MRJob \n",
    "    > Making files in s3 buckets public for distributed access\n",
    "    > Reading distributed files into mappers\n",
    "    > Iteration over MRJobs on AWS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Synonym detection and the nltk evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got one!\n",
      "\n",
      "railcar\n",
      "auto\n",
      "car\n",
      "automobile\n",
      "cable_car\n",
      "machine\n",
      "railway_car\n",
      "motorcar\n",
      "elevator_car\n",
      "gondola\n",
      "railroad_car\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python2.7\n",
    "''' pass a string to this funciton ( eg 'car') and it will give you a list of\n",
    "words which is related to cat, called lemma of CAT. '''\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import sys\n",
    "#print all the synset element of an element\n",
    "def synonyms(string):\n",
    "    syndict = {}\n",
    "    for i,j in enumerate(wn.synsets(string)):\n",
    "        syns = j.lemma_names()\n",
    "        for syn in syns:\n",
    "            syndict.setdefault(syn,1)\n",
    "    return syndict.keys()\n",
    "if 'auto' in synonyms(\"car\"):\n",
    "    print \"got one!\\n\"\n",
    "\n",
    "for syn in synonyms(\"car\"):\n",
    "    print syn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Google N-grams data and the AWS Command Line Interface (CLI)\n",
    "Here we will look at a brief example of the AWS CLI.\n",
    "In general the CLI makes it easy interact with data on Amazon's storage cluster (s3),\n",
    "and has many framiliar commands (e.g., cp, rm, etc...). For some general information on\n",
    "how to get set up with the AWS CLI, please follow the appropriate link for your platform\n",
    "starting at the following URL:\n",
    "\n",
    "    http://docs.aws.amazon.com/AWSEC2/latest/CommandLineReference/set-up-ec2-cli-linux.html\n",
    "    \n",
    "In the remainder of this tutorial, we will work with a filtered down sample of 10,000 5-grams\n",
    "from the google books project (shown below)---for reference, the data is tab-delimited,\n",
    "with the following columns:\n",
    "\n",
    "    (5-gram) \\t (total_count) \\t (books_count) \\t (pages_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Ball in Old Vienna\t131\t124\t63\r\n",
      "A Bibliography of First and\t44\t44\t42\r\n",
      "A Biographical Dictionary of Women\t222\t212\t156\r\n",
      "A Book of Ballads on\t48\t48\t48\r\n",
      "A Book of New Intellectual\t400\t400\t327\r\n",
      "A Brief Guide to the\t1291\t1244\t995\r\n",
      "A Case Study of Labor\t62\t61\t50\r\n",
      "A Commentary on the Method\t127\t125\t91\r\n",
      "A Commission of the European\t46\t46\t44\r\n",
      "A Constitutional Analysis of the\t187\t180\t132\r\n"
     ]
    }
   ],
   "source": [
    "!head -10 gbooks_filtered_sample.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Managing data on s3 with the AWS CLI\n",
    "We're not only going to want to make sure we can run our jobs on AWS, \n",
    "but also manage our data on the cloud using the AWS storage cluster, s3.\n",
    "Here is an example that uses the AWS CLI to copy our data up to a bucket\n",
    "(ucb-mids-mls-hw5) that we have created. To make your own bucket, try the following:\n",
    "\n",
    "    aws s3 mb s3://ucb-mids-mls-FirstnameLastname/\n",
    "\n",
    "or use the utility in the GUI console. Buckets may also be removed as follows:\n",
    "\n",
    "    aws s3 rb s3://ucb-mids-mls-FirstnameLastname/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_bucket: s3://ucb-mids-mls-hw5/gbooks_filtered_sample.txt/\n",
      "upload: ./gbooks_filtered_sample.txt to s3://ucb-mids-mls-hw5/gbooks_filtered_sample.txt\n"
     ]
    }
   ],
   "source": [
    "!aws s3 mb s3://ucb-mids-mls-hw5/gbooks_filtered_sample_sorted/\n",
    "!aws s3 cp gbooks_filtered_sample.txt s3://ucb-mids-mls-hw5/gbooks_filtered_sample.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###An example mrjob class that uses a non-default Hadoop sort\n",
    "In HW2, we were interested in doing a numeric sort on some integer keys (as strings)\n",
    "by leveraging the default Hadoop sort (in the shuffle). This required padding our\n",
    "integers as strings with zeros, so that the lexicographic sort would be equivilant \n",
    "to the desired numeric sort. However, this only got us to an increasing numeric sort,\n",
    "so, how can we get a decrasing (rank) numeric sort while using mrjob?\n",
    "####def jobconf(self):\n",
    "By defining this function in the mrjob class, we are able to pass parameters\n",
    "to the Hadoop streaming operation going on underneith mrjob. Look closely at\n",
    "this function in the script below, and notice that we merge the custom_jobconf \n",
    "configuration (with our sort parameters) with the default, so that we don't overide\n",
    "anything important from the default configuration that is not in our custom configuration.\n",
    "\n",
    "####Changing the sort order with jobconf(self):\n",
    "In the code below, we show how to change the default sort order, but there are many\n",
    "other custom configurations that are possible, e.g., partitioning by multiple keys.\n",
    "For some more general information and other good examples \n",
    "check out the following documentation:\n",
    "\n",
    "http://hadoop.apache.org/docs/r1.0.4/streaming.html#Hadoop+Comparator+Class\n",
    "\n",
    "Focusing in on the sort parameters in our custom configuration, we have:\n",
    ">'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "\n",
    "which will be the non-changing across your custom sorting needs, and\n",
    ">'mapred.text.key.comparator.options': '-k1rn',\n",
    "\n",
    "whose flags provide the functionality:\n",
    ">k1: sort by the first key (keys can be multi-part, with user-specified delimiters)\n",
    "\n",
    ">r: sort in reverse\n",
    "\n",
    ">n: sort numerically\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sortingExample.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sortingExample.py\n",
    "#!/usr/bin/python\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "from itertools import combinations\n",
    "\n",
    "class sortingExample(MRJob):\n",
    "    def jobconf(self):\n",
    "        orig_jobconf = super(sortingExample, self).jobconf()        \n",
    "        custom_jobconf = {\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k1rn',\n",
    "        }\n",
    "        combined_jobconf = orig_jobconf\n",
    "        combined_jobconf.update(custom_jobconf)\n",
    "        self.jobconf = combined_jobconf\n",
    "        return combined_jobconf\n",
    "    def steps(self):\n",
    "        return [MRStep(mapper = self.mapper, reducer = self.reducer)]\n",
    "    def mapper(self, _, line):\n",
    "        line.strip()\n",
    "        [ngram,count,pages,books] = re.split(\"\\t\",line)\n",
    "        yield int(count),ngram\n",
    "    def reducer(self,count,values):\n",
    "        for ngram in values:\n",
    "            yield ngram,count\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    sortingExample.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x sortingExample.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Run the sorting example locally and stream the output through STDOUT\n",
    "Just to make sure our mrjob class is working, we can check using our local copy of the data.\n",
    "Notice that our sort has not worked---this is because the custom config in our class will only\n",
    "work when our code is run on AWS, as we'll see below. Otherwise, things appear fine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using configs in /Users/jakerylandwilliams/.mrjob.conf\n",
      "creating tmp directory /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/sortingExample.jakerylandwilliams.20150928.220554.880307\n",
      "writing to /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/sortingExample.jakerylandwilliams.20150928.220554.880307/step-0-mapper_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "writing to /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/sortingExample.jakerylandwilliams.20150928.220554.880307/step-0-mapper-sorted\n",
      "> sort /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/sortingExample.jakerylandwilliams.20150928.220554.880307/step-0-mapper_part-00000\n",
      "writing to /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/sortingExample.jakerylandwilliams.20150928.220554.880307/step-0-reducer_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "Moving /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/sortingExample.jakerylandwilliams.20150928.220554.880307/step-0-reducer_part-00000 -> /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/sortingExample.jakerylandwilliams.20150928.220554.880307/output/part-00000\n",
      "Streaming final output from /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/sortingExample.jakerylandwilliams.20150928.220554.880307/output\n",
      "\"CO m m m CO\"\t1\n",
      "\"A Far Cry From Kensington\"\t100\n",
      "\"A compound of two or\"\t100\n",
      "\"A considerable number of churches\"\t100\n",
      "\"A method closely related to\"\t100\n",
      "\"Adding to the weight of\"\t100\n",
      "\"Among his latest works are\"\t100\n",
      "\"Arab which was bestrode by\"\t100\n",
      "\"At her love of wisdom\"\t100\n",
      "\"At length I saw an\"\t100\n",
      "\"At the annual commencement of\"\t100\n",
      "\"Being a quick reference to\"\t100\n",
      "\"British rule in India can\"\t100\n",
      "\"But the rattle of the\"\t100\n",
      "\"Charles had fallen in love\"\t100\n",
      "\"Copper in the United States\"\t100\n",
      "\"Diet and Disease in Traditional\"\t100\n",
      "\"Doppler echocardiographic evaluation of the\"\t100\n",
      "\"Dutch East Indies will be\"\t100\n",
      "\"Dutch drove the Portuguese from\"\t100\n",
      "\"East India Company by its\"\t100\n",
      "\"Elyot's The Boke named the\"\t100\n",
      "\"Even in the spring and\"\t100\n",
      "\"Florida and California in the\"\t100\n",
      "\"Given these limitations and the\"\t100\n",
      "\"He was good for me\"\t100\n",
      "\"Here too the answer is\"\t100\n",
      "\"I am not too surprised\"\t100\n",
      "\"I could move it with\"\t100\n",
      "\"I did not help the\"\t100\n",
      "\"I had lain awake all\"\t100\n",
      "\"I have given above from\"\t100\n",
      "\"I hope that he or\"\t100\n",
      "\"I ought to accept his\"\t100\n",
      "\"I shall be made Thy\"\t100\n",
      "\"I think they were some\"\t100\n",
      "\"Father and Creator of all\"\t1000\n",
      "\"He was possessed of an\"\t1001\n",
      "\"Feminist Consciousness and Feminist Research\"\t1003\n",
      "\"For I would not have\"\t1006\n",
      "\"I thought of how the\"\t1006\n",
      "\"A Mystery of American Letters\"\t101\n",
      "\"A book is to be\"\t101\n",
      "\"A is called the vertex\"\t101\n",
      "\"A patient in a state\"\t101\n",
      "\"Abassi Madani and Ali Belhadj\"\t101\n",
      "\"According to the tradition handed\"\t101\n",
      "\"Acknowledgments I thank the many\"\t101\n",
      "\"Additional Manuscripts of the British\"\t101\n",
      "\"Adult Children of Abusive Parents\"\t101\n",
      "removing tmp directory /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/sortingExample.jakerylandwilliams.20150928.220554.880307\n",
      "Traceback (most recent call last):\n",
      "  File \"./sortingExample.py\", line 29, in <module>\n",
      "    sortingExample.run()\n",
      "  File \"/usr/local/lib/python2.7/site-packages/mrjob/job.py\", line 461, in run\n",
      "    mr_job.execute()\n",
      "  File \"/usr/local/lib/python2.7/site-packages/mrjob/job.py\", line 479, in execute\n",
      "    super(MRJob, self).execute()\n",
      "  File \"/usr/local/lib/python2.7/site-packages/mrjob/launch.py\", line 153, in execute\n",
      "    self.run_job()\n",
      "  File \"/usr/local/lib/python2.7/site-packages/mrjob/launch.py\", line 220, in run_job\n",
      "    self.stdout.write(line)\n",
      "IOError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!./sortingExample.py gbooks_filtered_sample.txt | head -50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Running the sorting example on AWS with data from s3\n",
    "Here, we send our code up to AWS to meet the data at s3. Note the '-r emr'\n",
    "flags signaling an EMR job, in addition to the s3 url for our data in our bucket.\n",
    "If you look closely at the bottom, you'll see the output is reverse numeric sorted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using configs in /Users/jakerylandwilliams/.mrjob.conf\n",
      "using existing scratch bucket mrjob-070799b65f5ef217\n",
      "using s3://mrjob-070799b65f5ef217/tmp/ as our scratch dir on S3\n",
      "creating tmp directory /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/sortingExample.jakerylandwilliams.20150928.220814.786777\n",
      "writing master bootstrap script to /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/sortingExample.jakerylandwilliams.20150928.220814.786777/b.py\n",
      "Copying non-input files into s3://mrjob-070799b65f5ef217/tmp/sortingExample.jakerylandwilliams.20150928.220814.786777/files/\n",
      "Waiting 5.0s for S3 eventual consistency\n",
      "Creating Elastic MapReduce job flow\n",
      "Job flow created with ID: j-645UWBTVR1M4\n",
      "Created new job flow j-645UWBTVR1M4\n",
      "Job launched 30.9s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 62.2s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 93.1s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 124.3s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 155.2s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 186.4s ago, status BOOTSTRAPPING: Running bootstrap actions\n",
      "Job launched 217.3s ago, status BOOTSTRAPPING: Running bootstrap actions\n",
      "Job launched 248.5s ago, status BOOTSTRAPPING: Running bootstrap actions\n",
      "Job launched 279.4s ago, status BOOTSTRAPPING: Running bootstrap actions\n",
      "Job launched 310.3s ago, status RUNNING: Running step (sortingExample.jakerylandwilliams.20150928.220814.786777: Step 1 of 1)\n",
      "Job launched 342.0s ago, status RUNNING: Running step (sortingExample.jakerylandwilliams.20150928.220814.786777: Step 1 of 1)\n",
      "Job launched 372.9s ago, status RUNNING: Running step (sortingExample.jakerylandwilliams.20150928.220814.786777: Step 1 of 1)\n",
      "Job launched 404.0s ago, status RUNNING: Running step (sortingExample.jakerylandwilliams.20150928.220814.786777: Step 1 of 1)\n",
      "Job launched 434.9s ago, status RUNNING: Running step (sortingExample.jakerylandwilliams.20150928.220814.786777: Step 1 of 1)\n",
      "Job completed.\n",
      "Running time was 152.0s (not counting time spent waiting for the EC2 instances)\n",
      "ec2_key_pair_file not specified, going to S3\n",
      "Fetching counters from S3...\n",
      "Waiting 5.0s for S3 eventual consistency\n",
      "Counters from step 1:\n",
      "  File Input Format Counters :\n",
      "    Bytes Read: 391536\n",
      "  File Output Format Counters :\n",
      "    Bytes Written: 316994\n",
      "  FileSystemCounters:\n",
      "    FILE_BYTES_READ: 227413\n",
      "    FILE_BYTES_WRITTEN: 591120\n",
      "    HDFS_BYTES_READ: 404\n",
      "    S3_BYTES_READ: 391536\n",
      "    S3_BYTES_WRITTEN: 316994\n",
      "  Job Counters :\n",
      "    Launched map tasks: 4\n",
      "    Launched reduce tasks: 1\n",
      "    Rack-local map tasks: 4\n",
      "    SLOTS_MILLIS_MAPS: 94183\n",
      "    SLOTS_MILLIS_REDUCES: 42867\n",
      "    Total time spent by all maps waiting after reserving slots (ms): 0\n",
      "    Total time spent by all reduces waiting after reserving slots (ms): 0\n",
      "  Map-Reduce Framework:\n",
      "    CPU time spent (ms): 13760\n",
      "    Combine input records: 0\n",
      "    Combine output records: 0\n",
      "    Map input bytes: 363646\n",
      "    Map input records: 10000\n",
      "    Map output bytes: 316994\n",
      "    Map output materialized bytes: 229853\n",
      "    Map output records: 10000\n",
      "    Physical memory (bytes) snapshot: 875433984\n",
      "    Reduce input groups: 799\n",
      "    Reduce input records: 10000\n",
      "    Reduce output records: 10000\n",
      "    Reduce shuffle bytes: 229853\n",
      "    SPLIT_RAW_BYTES: 404\n",
      "    Spilled Records: 20000\n",
      "    Total committed heap usage (bytes): 607092736\n",
      "    Virtual memory (bytes) snapshot: 3222667264\n",
      "Streaming final output from s3://mrjob-070799b65f5ef217/tmp/sortingExample.jakerylandwilliams.20150928.220814.786777/output/\n",
      "\"I have no doubt that\"\t285570\n",
      "\"At a meeting of the\"\t104087\n",
      "\"I ought not to have\"\t34287\n",
      "\"I am not certain that\"\t19329\n",
      "\"I am struck by the\"\t12965\n",
      "\"But in the first place\"\t12026\n",
      "\"American University in Cairo Press\"\t8737\n",
      "\"From the above discussion it\"\t8617\n",
      "\"I have been reading the\"\t7962\n",
      "\"According to the nature of\"\t7723\n",
      "\"But by that time the\"\t7510\n",
      "\"I took it upon myself\"\t7379\n",
      "\"A new commandment I give\"\t6149\n",
      "\"How long would it be\"\t5449\n",
      "\"I am taking the liberty\"\t5067\n",
      "\"He died of a heart\"\t5063\n",
      "\"But I could see that\"\t4762\n",
      "\"History of the American Negro\"\t4704\n",
      "\"As with so many of\"\t4699\n",
      "\"Association of the University of\"\t4693\n",
      "\"I am trying to show\"\t4548\n",
      "\"I had been with the\"\t4520\n",
      "\"Although the results of the\"\t4228\n",
      "\"He carried with him a\"\t4208\n",
      "\"I have got to go\"\t4168\n",
      "\"I learned that there was\"\t4135\n",
      "\"I told myself it was\"\t4103\n",
      "\"I am in no mood\"\t4078\n",
      "\"I do not like you\"\t4067\n",
      "\"I thought it was about\"\t3997\n",
      "\"God has given to man\"\t3996\n",
      "\"Board of the Southern Baptist\"\t3946\n",
      "\"I do not feel so\"\t3780\n",
      "\"Houses of Parliament and the\"\t3736\n",
      "\"Guidelines for the Management of\"\t3624\n",
      "\"I fully agree with you\"\t3599\n",
      "\"His Excellency the Governor General\"\t3574\n",
      "\"At that time they had\"\t3452\n",
      "\"But I want to make\"\t3378\n",
      "\"An Archaeology of Medical Perception\"\t3324\n",
      "\"A fine example of the\"\t3295\n",
      "\"And what would you have\"\t3294\n",
      "\"As a man he was\"\t3065\n",
      "\"I felt that I might\"\t3048\n",
      "\"I have tried to emphasize\"\t3041\n",
      "\"He set to work to\"\t3016\n",
      "\"All this is very well\"\t2871\n",
      "\"Home Missions and Church Extension\"\t2847\n",
      "\"Awash in a Sea of\"\t2788\n",
      "\"Cloning and expression of the\"\t2784\n",
      "removing tmp directory /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/sortingExample.jakerylandwilliams.20150928.220814.786777\n",
      "Removing all files in s3://mrjob-070799b65f5ef217/tmp/sortingExample.jakerylandwilliams.20150928.220814.786777/\n",
      "Removing all files in s3://mrjob-070799b65f5ef217/tmp/logs/j-645UWBTVR1M4/\n",
      "Terminating job flow: j-645UWBTVR1M4\n",
      "Traceback (most recent call last):\n",
      "  File \"./sortingExample.py\", line 29, in <module>\n",
      "    sortingExample.run()\n",
      "  File \"/usr/local/lib/python2.7/site-packages/mrjob/job.py\", line 461, in run\n",
      "    mr_job.execute()\n",
      "  File \"/usr/local/lib/python2.7/site-packages/mrjob/job.py\", line 479, in execute\n",
      "    super(MRJob, self).execute()\n",
      "  File \"/usr/local/lib/python2.7/site-packages/mrjob/launch.py\", line 153, in execute\n",
      "    self.run_job()\n",
      "  File \"/usr/local/lib/python2.7/site-packages/mrjob/launch.py\", line 220, in run_job\n",
      "    self.stdout.write(line)\n",
      "IOError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!./sortingExample.py s3://ucb-mids-mls-hw5/gbooks_filtered_sample.txt -r emr | head -50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Storing output on s3\n",
    "Supposing we wish store the output of our job on s3 \n",
    "(which can then be available as input for, say, some other job), \n",
    "we can specify an ouput directory much as with Hadoop streaming.\n",
    "To do this, we will have to specify an output directoy (on s3) for mrjob:\n",
    "\n",
    "    --output-dir=s3://ucb-mids-mls-hw5/gbooks_filtered_sample_sorted \n",
    "    \n",
    "However, this will not stop the stream of output back to our local machine,\n",
    "which is accomplished by the separate parameter:\n",
    "\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using configs in /Users/jakerylandwilliams/.mrjob.conf\n",
      "using existing scratch bucket mrjob-070799b65f5ef217\n",
      "using s3://mrjob-070799b65f5ef217/tmp/ as our scratch dir on S3\n",
      "creating tmp directory /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/sortingExample.jakerylandwilliams.20150929.044057.664324\n",
      "writing master bootstrap script to /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/sortingExample.jakerylandwilliams.20150929.044057.664324/b.py\n",
      "Copying non-input files into s3://mrjob-070799b65f5ef217/tmp/sortingExample.jakerylandwilliams.20150929.044057.664324/files/\n",
      "Waiting 5.0s for S3 eventual consistency\n",
      "Creating Elastic MapReduce job flow\n",
      "Job flow created with ID: j-NERAUZK08MKU\n",
      "Created new job flow j-NERAUZK08MKU\n",
      "Job launched 35.4s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 66.7s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 98.0s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 129.2s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 160.1s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 191.4s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 222.5s ago, status BOOTSTRAPPING: Running bootstrap actions\n",
      "Job launched 253.9s ago, status BOOTSTRAPPING: Running bootstrap actions\n",
      "Job launched 284.8s ago, status BOOTSTRAPPING: Running bootstrap actions\n",
      "Job launched 315.9s ago, status BOOTSTRAPPING: Running bootstrap actions\n",
      "Job launched 346.9s ago, status RUNNING: Running step (sortingExample.jakerylandwilliams.20150929.044057.664324: Step 1 of 1)\n",
      "Job launched 379.6s ago, status RUNNING: Running step (sortingExample.jakerylandwilliams.20150929.044057.664324: Step 1 of 1)\n",
      "Job launched 410.7s ago, status RUNNING: Running step (sortingExample.jakerylandwilliams.20150929.044057.664324: Step 1 of 1)\n",
      "Job launched 441.6s ago, status RUNNING: Running step (sortingExample.jakerylandwilliams.20150929.044057.664324: Step 1 of 1)\n",
      "Job completed.\n",
      "Running time was 125.0s (not counting time spent waiting for the EC2 instances)\n",
      "ec2_key_pair_file not specified, going to S3\n",
      "Fetching counters from S3...\n",
      "Waiting 5.0s for S3 eventual consistency\n",
      "Counters from step 1:\n",
      "  File Input Format Counters :\n",
      "    Bytes Read: 391536\n",
      "  File Output Format Counters :\n",
      "    Bytes Written: 316994\n",
      "  FileSystemCounters:\n",
      "    FILE_BYTES_READ: 227413\n",
      "    FILE_BYTES_WRITTEN: 590860\n",
      "    HDFS_BYTES_READ: 404\n",
      "    S3_BYTES_READ: 391536\n",
      "    S3_BYTES_WRITTEN: 316994\n",
      "  Job Counters :\n",
      "    Launched map tasks: 4\n",
      "    Launched reduce tasks: 1\n",
      "    Rack-local map tasks: 4\n",
      "    SLOTS_MILLIS_MAPS: 82268\n",
      "    SLOTS_MILLIS_REDUCES: 39665\n",
      "    Total time spent by all maps waiting after reserving slots (ms): 0\n",
      "    Total time spent by all reduces waiting after reserving slots (ms): 0\n",
      "  Map-Reduce Framework:\n",
      "    CPU time spent (ms): 11900\n",
      "    Combine input records: 0\n",
      "    Combine output records: 0\n",
      "    Map input bytes: 363646\n",
      "    Map input records: 10000\n",
      "    Map output bytes: 316994\n",
      "    Map output materialized bytes: 229853\n",
      "    Map output records: 10000\n",
      "    Physical memory (bytes) snapshot: 874852352\n",
      "    Reduce input groups: 799\n",
      "    Reduce input records: 10000\n",
      "    Reduce output records: 10000\n",
      "    Reduce shuffle bytes: 229853\n",
      "    SPLIT_RAW_BYTES: 404\n",
      "    Spilled Records: 20000\n",
      "    Total committed heap usage (bytes): 606928896\n",
      "    Virtual memory (bytes) snapshot: 3220131840\n",
      "removing tmp directory /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/sortingExample.jakerylandwilliams.20150929.044057.664324\n",
      "Removing all files in s3://mrjob-070799b65f5ef217/tmp/sortingExample.jakerylandwilliams.20150929.044057.664324/\n",
      "Removing all files in s3://mrjob-070799b65f5ef217/tmp/logs/j-NERAUZK08MKU/\n",
      "Terminating job flow: j-NERAUZK08MKU\n"
     ]
    }
   ],
   "source": [
    "!./sortingExample.py s3://ucb-mids-mls-hw5/gbooks_filtered_sample.txt -r emr \\\n",
    "    --output-dir=s3://ucb-mids-mls-hw5/gbooks_filtered_sample_sorted \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Download our output and clean things up a little\n",
    "To access our stored data, we once again can use the AWS CLI tool, 'cp.'\n",
    "To download our program's output, we must look inside of the specified target directory \n",
    "for the usual Hadoop output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://ucb-mids-mls-hw5/gbooks_filtered_sample_sorted/part-00000 to ./gbooks_filtered_sample_sorted.txt\n",
      "delete: s3://ucb-mids-mls-hw5/gbooks_filtered_sample_sorted/part-00000\n",
      "delete: s3://ucb-mids-mls-hw5/gbooks_filtered_sample_sorted/_SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://ucb-mids-mls-hw5/gbooks_filtered_sample_sorted/part-00000 gbooks_filtered_sample_sorted.txt\n",
    "!aws s3 rm s3://ucb-mids-mls-hw5/gbooks_filtered_sample_sorted/part-00000\n",
    "!aws s3 rm s3://ucb-mids-mls-hw5/gbooks_filtered_sample_sorted/_SUCCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Check on our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I have no doubt that\"\t285570\r\n",
      "\"At a meeting of the\"\t104087\r\n",
      "\"I ought not to have\"\t34287\r\n",
      "\"I am not certain that\"\t19329\r\n",
      "\"I am struck by the\"\t12965\r\n",
      "\"But in the first place\"\t12026\r\n",
      "\"American University in Cairo Press\"\t8737\r\n",
      "\"From the above discussion it\"\t8617\r\n",
      "\"I have been reading the\"\t7962\r\n",
      "\"According to the nature of\"\t7723\r\n",
      "\"But by that time the\"\t7510\r\n",
      "\"I took it upon myself\"\t7379\r\n",
      "\"A new commandment I give\"\t6149\r\n",
      "\"How long would it be\"\t5449\r\n",
      "\"I am taking the liberty\"\t5067\r\n",
      "\"He died of a heart\"\t5063\r\n",
      "\"But I could see that\"\t4762\r\n",
      "\"History of the American Negro\"\t4704\r\n",
      "\"As with so many of\"\t4699\r\n",
      "\"Association of the University of\"\t4693\r\n",
      "\"I am trying to show\"\t4548\r\n",
      "\"I had been with the\"\t4520\r\n",
      "\"Although the results of the\"\t4228\r\n",
      "\"He carried with him a\"\t4208\r\n",
      "\"I have got to go\"\t4168\r\n",
      "\"I learned that there was\"\t4135\r\n",
      "\"I told myself it was\"\t4103\r\n",
      "\"I am in no mood\"\t4078\r\n",
      "\"I do not like you\"\t4067\r\n",
      "\"I thought it was about\"\t3997\r\n",
      "\"God has given to man\"\t3996\r\n",
      "\"Board of the Southern Baptist\"\t3946\r\n",
      "\"I do not feel so\"\t3780\r",
      "\r\n",
      "\"Houses of Parliament and the\"\t3736\r\n",
      "\"Guidelines for the Management of\"\t3624\r\n",
      "\"I fully agree with you\"\t3599\r\n",
      "\"His Excellency the Governor General\"\t3574\r\n",
      "\"At that time they had\"\t3452\r\n",
      "\"But I want to make\"\t3378\r\n",
      "\"An Archaeology of Medical Perception\"\t3324\r\n",
      "\"A fine example of the\"\t3295\r\n",
      "\"And what would you have\"\t3294\r\n",
      "\"As a man he was\"\t3065\r\n",
      "\"I felt that I might\"\t3048\r\n",
      "\"I have tried to emphasize\"\t3041\r\n",
      "\"He set to work to\"\t3016\r\n",
      "\"All this is very well\"\t2871\r\n",
      "\"Home Missions and Church Extension\"\t2847\r\n",
      "\"Awash in a Sea of\"\t2788\r\n",
      "\"Cloning and expression of the\"\t2784\r\n"
     ]
    }
   ],
   "source": [
    "!head -50 gbooks_filtered_sample_sorted.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Running our job from a python driver\n",
    "Much as we have already seen before, we can run our job with data from s3\n",
    "from a driver that will recieve streaming output---just place the s3 URL\n",
    "for the main data file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sortingExample_driver.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sortingExample_driver.py\n",
    "#!/usr/bin/python\n",
    "from sortingExample import sortingExample\n",
    "mr_job = sortingExample(args=['s3://ucb-mids-mls-hw5/gbooks_filtered_sample.txt','-r', 'emr'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        ngram,count = mr_job.parse_output_line(line)\n",
    "        print ngram + \"\\t\" + str(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x sortingExample_driver.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have no doubt that\t285570\n",
      "At a meeting of the\t104087\n",
      "I ought not to have\t34287\n",
      "I am not certain that\t19329\n",
      "I am struck by the\t12965\n",
      "But in the first place\t12026\n",
      "American University in Cairo Press\t8737\n",
      "From the above discussion it\t8617\n",
      "I have been reading the\t7962\n",
      "According to the nature of\t7723\n",
      "But by that time the\t7510\n",
      "I took it upon myself\t7379\n",
      "A new commandment I give\t6149\n",
      "How long would it be\t5449\n",
      "I am taking the liberty\t5067\n",
      "He died of a heart\t5063\n",
      "But I could see that\t4762\n",
      "History of the American Negro\t4704\n",
      "As with so many of\t4699\n",
      "Association of the University of\t4693\n",
      "I am trying to show\t4548\n",
      "I had been with the\t4520\n",
      "Although the results of the\t4228\n",
      "He carried with him a\t4208\n",
      "I have got to go\t4168\n",
      "I learned that there was\t4135\n",
      "I told myself it was\t4103\n",
      "I am in no mood\t4078\n",
      "I do not like you\t4067\n",
      "I thought it was about\t3997\n",
      "God has given to man\t3996\n",
      "Board of the Southern Baptist\t3946\n",
      "I do not feel so\t3780\n",
      "Houses of Parliament and the\t3736\n",
      "Guidelines for the Management of\t3624\n",
      "I fully agree with you\t3599\n",
      "His Excellency the Governor General\t3574\n",
      "At that time they had\t3452\n",
      "But I want to make\t3378\n",
      "An Archaeology of Medical Perception\t3324\n",
      "A fine example of the\t3295\n",
      "And what would you have\t3294\n",
      "As a man he was\t3065\n",
      "I felt that I might\t3048\n",
      "I have tried to emphasize\t3041\n",
      "He set to work to\t3016\n",
      "All this is very well\t2871\n",
      "Home Missions and Church Extension\t2847\n",
      "Awash in a Sea of\t2788\n",
      "Cloning and expression of the\t2784\n",
      "Traceback (most recent call last):\n",
      "  File \"./sortingExample_driver.py\", line 9, in <module>\n",
      "    print ngram + \"\\t\" + str(count)\n",
      "IOError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!./sortingExample_driver.py | head -50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Reading and writing cached data\n",
    "###Writing to s3\n",
    "Sometimes (as is required with and iterative implementation of the Apriori algorithm) \n",
    "we will need to store data from one job and broadcast it to the mappers in another job.\n",
    "This first MRJob class will start an implementation of the apriori algorithm for \n",
    "the words inside of our 5-grams, here storing the 1-gram (word) frequent support on s3,\n",
    "via the \n",
    "\n",
    "    --output-dir=s3://ucb-mids-mls-hw5/readWriteExample_output\n",
    "    \n",
    "command line parameter. This will then force us to use the AWS CLI to copy our data \n",
    "from the usual Hadoop output pattern:\n",
    "\n",
    "    s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting writeExample.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile writeExample.py\n",
    "#!/usr/bin/python\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "from itertools import combinations\n",
    "\n",
    "class writeExample(MRJob):\n",
    "    thresh = 1000\n",
    "    def steps(self):\n",
    "        return [MRStep(\n",
    "                mapper = self.mapper, \n",
    "                reducer = self.reducer\n",
    "            )]\n",
    "    def mapper(self, _, line):\n",
    "        line.strip()\n",
    "        [ngram,count,pages,books] = re.split(\"\\t\",line)\n",
    "        words = re.split(\" \",ngram)\n",
    "        count = int(count)\n",
    "        for word in words:\n",
    "            yield word,count\n",
    "    def reducer(self,word,values):\n",
    "        count = sum(values)\n",
    "        if count >= self.thresh:\n",
    "            yield word,count\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    writeExample.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x writeExample.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using configs in /Users/jakerylandwilliams/.mrjob.conf\n",
      "using existing scratch bucket mrjob-070799b65f5ef217\n",
      "using s3://mrjob-070799b65f5ef217/tmp/ as our scratch dir on S3\n",
      "creating tmp directory /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/writeExample.jakerylandwilliams.20150930.215411.663562\n",
      "writing master bootstrap script to /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/writeExample.jakerylandwilliams.20150930.215411.663562/b.py\n",
      "Copying non-input files into s3://mrjob-070799b65f5ef217/tmp/writeExample.jakerylandwilliams.20150930.215411.663562/files/\n",
      "Waiting 5.0s for S3 eventual consistency\n",
      "Creating Elastic MapReduce job flow\n",
      "Job flow created with ID: j-X3XVQZPI1UZX\n",
      "Created new job flow j-X3XVQZPI1UZX\n",
      "Job launched 30.9s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 62.1s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 93.0s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 124.1s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 155.0s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 185.9s ago, status BOOTSTRAPPING: Running bootstrap actions\n",
      "Job launched 216.9s ago, status BOOTSTRAPPING: Running bootstrap actions\n",
      "Job launched 248.0s ago, status BOOTSTRAPPING: Running bootstrap actions\n",
      "Job launched 279.1s ago, status BOOTSTRAPPING: Running bootstrap actions\n",
      "Job launched 310.0s ago, status RUNNING: Running step (writeExample.jakerylandwilliams.20150930.215411.663562: Step 1 of 1)\n",
      "Job launched 341.1s ago, status RUNNING: Running step (writeExample.jakerylandwilliams.20150930.215411.663562: Step 1 of 1)\n",
      "Job launched 375.9s ago, status RUNNING: Running step (writeExample.jakerylandwilliams.20150930.215411.663562: Step 1 of 1)\n",
      "Job launched 407.3s ago, status RUNNING: Running step (writeExample.jakerylandwilliams.20150930.215411.663562: Step 1 of 1)\n",
      "Job launched 438.3s ago, status RUNNING: Running step (writeExample.jakerylandwilliams.20150930.215411.663562: Step 1 of 1)\n",
      "Job completed.\n",
      "Running time was 150.0s (not counting time spent waiting for the EC2 instances)\n",
      "ec2_key_pair_file not specified, going to S3\n",
      "Fetching counters from S3...\n",
      "Waiting 5.0s for S3 eventual consistency\n",
      "Counters from step 1:\n",
      "  File Input Format Counters :\n",
      "    Bytes Read: 391536\n",
      "  File Output Format Counters :\n",
      "    Bytes Written: 10607\n",
      "  FileSystemCounters:\n",
      "    FILE_BYTES_READ: 270487\n",
      "    FILE_BYTES_WRITTEN: 707769\n",
      "    HDFS_BYTES_READ: 404\n",
      "    S3_BYTES_READ: 391536\n",
      "    S3_BYTES_WRITTEN: 10607\n",
      "  Job Counters :\n",
      "    Launched map tasks: 4\n",
      "    Launched reduce tasks: 1\n",
      "    Rack-local map tasks: 4\n",
      "    SLOTS_MILLIS_MAPS: 119053\n",
      "    SLOTS_MILLIS_REDUCES: 61313\n",
      "    Total time spent by all maps waiting after reserving slots (ms): 0\n",
      "    Total time spent by all reduces waiting after reserving slots (ms): 0\n",
      "  Map-Reduce Framework:\n",
      "    CPU time spent (ms): 15600\n",
      "    Combine input records: 0\n",
      "    Combine output records: 0\n",
      "    Map input bytes: 363646\n",
      "    Map input records: 10000\n",
      "    Map output bytes: 531166\n",
      "    Map output materialized bytes: 304873\n",
      "    Map output records: 50000\n",
      "    Physical memory (bytes) snapshot: 874668032\n",
      "    Reduce input groups: 8615\n",
      "    Reduce input records: 50000\n",
      "    Reduce output records: 776\n",
      "    Reduce shuffle bytes: 304873\n",
      "    SPLIT_RAW_BYTES: 404\n",
      "    Spilled Records: 100000\n",
      "    Total committed heap usage (bytes): 606842880\n",
      "    Virtual memory (bytes) snapshot: 3236454400\n",
      "removing tmp directory /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/writeExample.jakerylandwilliams.20150930.215411.663562\n",
      "Removing all files in s3://mrjob-070799b65f5ef217/tmp/writeExample.jakerylandwilliams.20150930.215411.663562/\n",
      "Removing all files in s3://mrjob-070799b65f5ef217/tmp/logs/j-X3XVQZPI1UZX/\n",
      "Terminating job flow: j-X3XVQZPI1UZX\n"
     ]
    }
   ],
   "source": [
    "!./writeExample.py s3://ucb-mids-mls-hw5/gbooks_filtered_sample.txt -r emr \\\n",
    "    --output-dir=s3://ucb-mids-mls-hw5/readWriteExample_output \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Copy to local and examine output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000 to ./frequentSupport.txt\n",
      "\"A\"\t74206\n",
      "\"AND\"\t3684\n",
      "\"Abbott\"\t1758\n",
      "\"About\"\t1805\n",
      "\"Academy\"\t1100\n",
      "\"According\"\t10013\n",
      "\"Account\"\t1152\n",
      "\"Act\"\t4238\n",
      "\"Africa\"\t1928\n",
      "\"After\"\t12056\n",
      "\"Age\"\t1468\n",
      "\"Ages\"\t1093\n",
      "\"All\"\t13245\n",
      "\"Although\"\t13899\n",
      "\"Alvin\"\t2561\n",
      "\"America\"\t5649\n",
      "\"American\"\t25879\n",
      "\"Americans\"\t1616\n",
      "\"Among\"\t3895\n",
      "\"An\"\t16379\n",
      "\"Analysis\"\t4320\n",
      "\"And\"\t44804\n",
      "\"Annual\"\t1344\n",
      "\"Anomalous\"\t1706\n",
      "\"Another\"\t3324\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000 ./frequentSupport.txt\n",
    "!head -25 frequentSupport.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Clean things up and store our output on s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000 to s3://ucb-mids-mls-hw5/frequentSupport.txt\n",
      "delete: s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000\n",
      "delete: s3://ucb-mids-mls-hw5/readWriteExample_output/_SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000 s3://ucb-mids-mls-hw5/frequentSupport.txt\n",
    "!aws s3 rm s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000\n",
    "!aws s3 rm s3://ucb-mids-mls-hw5/readWriteExample_output/_SUCCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Reading cached files from s3\n",
    "We have already stored our output from the previous job in our bucket:\n",
    "\n",
    "    s3://ucb-mids-mls-hw5/frequentSupport.txt,\n",
    "\n",
    "but to read cached files from s3, we will have to make our bucket public, \n",
    "\n",
    "    http://tiffanybbrown.com/2014/09/making-all-objects-in-an-s3-bucket-public-by-default/\n",
    "\n",
    "so that its contents will be acessible from the url format:\n",
    "\n",
    "    https://s3-us-west-2.amazonaws.com/ucb-mids-mls-hw5/frequentSupport.txt\n",
    "    \n",
    "while using the python commands\n",
    "\n",
    "    import urllib2\n",
    "    \n",
    "    f = urllib2.urlopen(URL)\n",
    "    for line in f.readlines():\n",
    "    ...\n",
    "    \n",
    "discussed in the AWS forum:\n",
    "\n",
    "    https://forums.aws.amazon.com/thread.jspa?messageID=341543\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting readWriteExample.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile readWriteExample.py\n",
    "#!/usr/bin/python\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "from itertools import combinations\n",
    "import urllib2\n",
    "\n",
    "class readWriteExample(MRJob):\n",
    "    thresh = 1000\n",
    "    N = 0\n",
    "    freqSupport = {}\n",
    "    def steps(self):\n",
    "        return [MRStep(\n",
    "                mapper_init = self.mapper_init,\n",
    "                mapper = self.mapper,\n",
    "                reducer = self.reducer\n",
    "            )]\n",
    "    def mapper_init(self):\n",
    "        f = urllib2.urlopen(\"https://s3-us-west-2.amazonaws.com/ucb-mids-mls-hw5/frequentSupport.txt\")\n",
    "        for line in f.readlines():\n",
    "            line.strip()\n",
    "            ### because the yielded output produces quotes!\n",
    "            line = re.sub(\"\\\"\",\"\",line)\n",
    "            ngram,count = re.split(\"\\t\",line)\n",
    "            self.freqSupport[ngram] = int(count)\n",
    "            if self.N == 0:\n",
    "                self.N = len(re.split(\",\",ngram))+1\n",
    "    def mapper(self, _, line):\n",
    "        line.strip()\n",
    "        [ngram,count,pages,books] = re.split(\"\\t\",line)\n",
    "        words = re.split(\" \",ngram)\n",
    "        count = int(count)\n",
    "        combs = list(combinations(words,self.N))\n",
    "        subSize = self.N-1\n",
    "        for combination in combs:\n",
    "            wordSet = \",\".join(sorted(combination))\n",
    "            subCombs = list(combinations(combination,subSize))\n",
    "            subsFrequent = 1\n",
    "            for subComb in subCombs:\n",
    "                subWordSet = \",\".join(sorted(subComb))\n",
    "                if subWordSet not in self.freqSupport:\n",
    "                    subsFrequent = 0\n",
    "                    break\n",
    "            if subsFrequent:\n",
    "                yield wordSet,count\n",
    "    def reducer(self,wordSet,values):\n",
    "        count = sum(values)\n",
    "        if count >= self.thresh:\n",
    "            yield wordSet,count\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    readWriteExample.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using configs in /Users/jakerylandwilliams/.mrjob.conf\n",
      "using existing scratch bucket mrjob-070799b65f5ef217\n",
      "using s3://mrjob-070799b65f5ef217/tmp/ as our scratch dir on S3\n",
      "creating tmp directory /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/readWriteExample.jakerylandwilliams.20150930.212100.551496\n",
      "writing master bootstrap script to /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/readWriteExample.jakerylandwilliams.20150930.212100.551496/b.py\n",
      "Copying non-input files into s3://mrjob-070799b65f5ef217/tmp/readWriteExample.jakerylandwilliams.20150930.212100.551496/files/\n",
      "Waiting 5.0s for S3 eventual consistency\n",
      "Creating Elastic MapReduce job flow\n",
      "Job flow created with ID: j-1LFH4ZRUN5XBD\n",
      "Created new job flow j-1LFH4ZRUN5XBD\n",
      "Job launched 30.9s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 62.1s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 93.0s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 124.2s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 155.1s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 186.0s ago, status STARTING: Provisioning Amazon EC2 capacity\n",
      "Job launched 217.0s ago, status STARTING: Configuring cluster software\n",
      "Job launched 248.0s ago, status BOOTSTRAPPING: Running bootstrap actions\n",
      "Job launched 279.1s ago, status BOOTSTRAPPING: Running bootstrap actions\n",
      "Job launched 310.3s ago, status BOOTSTRAPPING: Running bootstrap actions\n",
      "Job launched 341.3s ago, status BOOTSTRAPPING: Running bootstrap actions\n",
      "Job launched 372.4s ago, status RUNNING: Running step (readWriteExample.jakerylandwilliams.20150930.212100.551496: Step 1 of 1)\n",
      "Job launched 403.5s ago, status RUNNING: Running step (readWriteExample.jakerylandwilliams.20150930.212100.551496: Step 1 of 1)\n",
      "Job launched 434.4s ago, status RUNNING: Running step (readWriteExample.jakerylandwilliams.20150930.212100.551496: Step 1 of 1)\n",
      "Job launched 465.2s ago, status RUNNING: Running step (readWriteExample.jakerylandwilliams.20150930.212100.551496: Step 1 of 1)\n",
      "Job launched 496.4s ago, status RUNNING: Running step (readWriteExample.jakerylandwilliams.20150930.212100.551496: Step 1 of 1)\n",
      "Job completed.\n",
      "Running time was 131.0s (not counting time spent waiting for the EC2 instances)\n",
      "ec2_key_pair_file not specified, going to S3\n",
      "Fetching counters from S3...\n",
      "Waiting 5.0s for S3 eventual consistency\n",
      "Counters from step 1:\n",
      "  File Input Format Counters :\n",
      "    Bytes Read: 391536\n",
      "  File Output Format Counters :\n",
      "    Bytes Written: 38148\n",
      "  FileSystemCounters:\n",
      "    FILE_BYTES_READ: 376111\n",
      "    FILE_BYTES_WRITTEN: 906858\n",
      "    HDFS_BYTES_READ: 404\n",
      "    S3_BYTES_READ: 391536\n",
      "    S3_BYTES_WRITTEN: 38148\n",
      "  Job Counters :\n",
      "    Launched map tasks: 4\n",
      "    Launched reduce tasks: 1\n",
      "    Rack-local map tasks: 4\n",
      "    SLOTS_MILLIS_MAPS: 103541\n",
      "    SLOTS_MILLIS_REDUCES: 42187\n",
      "    Total time spent by all maps waiting after reserving slots (ms): 0\n",
      "    Total time spent by all reduces waiting after reserving slots (ms): 0\n",
      "  Map-Reduce Framework:\n",
      "    CPU time spent (ms): 17610\n",
      "    Combine input records: 0\n",
      "    Combine output records: 0\n",
      "    Map input bytes: 363646\n",
      "    Map input records: 10000\n",
      "    Map output bytes: 763514\n",
      "    Map output materialized bytes: 398223\n",
      "    Map output records: 54025\n",
      "    Physical memory (bytes) snapshot: 878465024\n",
      "    Reduce input groups: 16888\n",
      "    Reduce input records: 54025\n",
      "    Reduce output records: 2252\n",
      "    Reduce shuffle bytes: 398223\n",
      "    SPLIT_RAW_BYTES: 404\n",
      "    Spilled Records: 108050\n",
      "    Total committed heap usage (bytes): 606826496\n",
      "    Virtual memory (bytes) snapshot: 3049496576\n",
      "removing tmp directory /var/folders/3y/665tnx6s0jjcysf043nfcwm80000gn/T/readWriteExample.jakerylandwilliams.20150930.212100.551496\n",
      "Removing all files in s3://mrjob-070799b65f5ef217/tmp/readWriteExample.jakerylandwilliams.20150930.212100.551496/\n",
      "Removing all files in s3://mrjob-070799b65f5ef217/tmp/logs/j-1LFH4ZRUN5XBD/\n",
      "Terminating job flow: j-1LFH4ZRUN5XBD\n"
     ]
    }
   ],
   "source": [
    "!./readWriteExample.py s3://ucb-mids-mls-hw5/gbooks_filtered_sample.txt -r emr \\\n",
    "    --output-dir=s3://ucb-mids-mls-hw5/readWriteExample_output \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Copy to local and examine output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000 to ./frequentSupport_2.txt\n",
      "\"A,B\"\t1426\n",
      "\"A,Brief\"\t1291\n",
      "\"A,DAYS\"\t1331\n",
      "\"A,FOURTEEN\"\t1331\n",
      "\"A,Guide\"\t1337\n",
      "\"A,History\"\t1041\n",
      "\"A,I\"\t6513\n",
      "\"A,a\"\t4685\n",
      "\"A,and\"\t3988\n",
      "\"A,at\"\t2634\n",
      "\"A,commandment\"\t6149\n",
      "\"A,council\"\t1174\n",
      "\"A,example\"\t3345\n",
      "\"A,fair\"\t1291\n",
      "\"A,few\"\t2407\n",
      "\"A,fine\"\t4722\n",
      "\"A,for\"\t2735\n",
      "\"A,from\"\t1530\n",
      "\"A,give\"\t6149\n",
      "\"A,good\"\t1035\n",
      "\"A,held\"\t1245\n",
      "\"A,in\"\t3620\n",
      "\"A,is\"\t5518\n",
      "\"A,large\"\t1097\n",
      "\"A,later\"\t2546\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000 ./frequentSupport_2.txt\n",
    "!head -25 frequentSupport_2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###We can package this all in a driver for iteration, too\n",
    "####Clean up a little first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A client error (404) occurred when calling the HeadObject operation: Key \"readWriteExample_output/part-00000\" does not exist\n",
      "Completed 1 part(s) with ... file(s) remaining\n",
      "A client error (404) occurred when calling the HeadObject operation: Key \"readWriteExample_output/_SUCCESS\" does not exist\n",
      "Completed 1 part(s) with ... file(s) remaining\n",
      "delete: s3://ucb-mids-mls-hw5/frequentSupport.txt\n"
     ]
    }
   ],
   "source": [
    "!aws s3 rm s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000\n",
    "!aws s3 rm s3://ucb-mids-mls-hw5/readWriteExample_output/_SUCCESS\n",
    "!aws s3 rm s3://ucb-mids-mls-hw5/frequentSupport.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting readWriteExample_driver.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile readWriteExample_driver.py\n",
    "#!/usr/bin/python\n",
    "from writeExample import writeExample\n",
    "from readWriteExample import readWriteExample\n",
    "\n",
    "import os\n",
    "\n",
    "mr_job = writeExample(args=[\n",
    "        's3://ucb-mids-mls-hw5/gbooks_filtered_sample.txt',\n",
    "        '-r', 'emr',\n",
    "        '--output-dir=s3://ucb-mids-mls-hw5/readWriteExample_output',\n",
    "        '--no-output'\n",
    "    ])\n",
    "\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "os.system(\"aws s3 cp s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000 s3://ucb-mids-mls-hw5/frequentSupport.txt\")\n",
    "os.system(\"aws s3 rm s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000\")\n",
    "os.system(\"aws s3 rm s3://ucb-mids-mls-hw5/readWriteExample_output/_SUCCESS\")\n",
    "\n",
    "for i in range(2):\n",
    "    mr_job = readWriteExample(args=[\n",
    "            's3://ucb-mids-mls-hw5/gbooks_filtered_sample.txt',\n",
    "            '-r', 'emr',\n",
    "            '--output-dir=s3://ucb-mids-mls-hw5/readWriteExample_output',\n",
    "            '--no-output'\n",
    "        ])\n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        os.system(\"aws s3 cp s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000 s3://ucb-mids-mls-hw5/frequentSupport.txt\")\n",
    "        os.system(\"aws s3 rm s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000\")\n",
    "        os.system(\"aws s3 rm s3://ucb-mids-mls-hw5/readWriteExample_output/_SUCCESS\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!chmod +x writeExample.py readWriteExample.py readWriteExample_driver.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000 to s3://ucb-mids-mls-hw5/frequentSupport.txt\n",
      "delete: s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000\n",
      "delete: s3://ucb-mids-mls-hw5/readWriteExample_output/_SUCCESS\n",
      "copy: s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000 to s3://ucb-mids-mls-hw5/frequentSupport.txt\n",
      "delete: s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000\n",
      "delete: s3://ucb-mids-mls-hw5/readWriteExample_output/_SUCCESS\n",
      "copy: s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000 to s3://ucb-mids-mls-hw5/frequentSupport.txt\n",
      "delete: s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000\n",
      "delete: s3://ucb-mids-mls-hw5/readWriteExample_output/_SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!./readWriteExample_driver.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Check on the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://ucb-mids-mls-hw5/frequentSupport.txt to ./frequentSupport_3.txt\n",
      "\"A,B,and\"\t1244\n",
      "\"A,Brief,Guide\"\t1291\n",
      "\"A,Brief,the\"\t1291\n",
      "\"A,Brief,to\"\t1291\n",
      "\"A,DAYS,FOURTEEN\"\t1331\n",
      "\"A,DAYS,fine\"\t1331\n",
      "\"A,DAYS,of\"\t1331\n",
      "\"A,FOURTEEN,fine\"\t1331\n",
      "\"A,FOURTEEN,of\"\t1331\n",
      "\"A,Guide,the\"\t1337\n",
      "\"A,Guide,to\"\t1291\n",
      "\"A,History,of\"\t1041\n",
      "\"A,I,commandment\"\t6149\n",
      "\"A,I,give\"\t6149\n",
      "\"A,I,new\"\t6149\n",
      "\"A,a,few\"\t1821\n",
      "\"A,a,is\"\t1711\n",
      "\"A,a,later\"\t1909\n",
      "\"A,a,seconds\"\t1821\n",
      "\"A,and,of\"\t1072\n",
      "\"A,at,council\"\t1174\n",
      "\"A,at,held\"\t1174\n",
      "\"A,at,was\"\t1281\n",
      "\"A,commandment,give\"\t6149\n",
      "\"A,commandment,new\"\t6149\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://ucb-mids-mls-hw5/frequentSupport.txt ./frequentSupport_3.txt\n",
    "!head -25 frequentSupport_3.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A client error (404) occurred when calling the HeadObject operation: Key \"readWriteExample_output/part-00000\" does not exist\n",
      "Completed 1 part(s) with ... file(s) remaining\n",
      "A client error (404) occurred when calling the HeadObject operation: Key \"readWriteExample_output/_SUCCESS\" does not exist\n",
      "Completed 1 part(s) with ... file(s) remaining\n",
      "delete: s3://ucb-mids-mls-hw5/frequentSupport.txt\n"
     ]
    }
   ],
   "source": [
    "!aws s3 rm s3://ucb-mids-mls-hw5/readWriteExample_output/part-00000\n",
    "!aws s3 rm s3://ucb-mids-mls-hw5/readWriteExample_output/_SUCCESS\n",
    "!aws s3 rm s3://ucb-mids-mls-hw5/frequentSupport.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
