{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#DATASCI W261: Machine Learning at Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MrJob class for Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want to change the code, please edit Kmeans.py directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Kmeans.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Kmeans.py\n",
    "from numpy import argmin, array, random\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from itertools import chain\n",
    "import math\n",
    "\n",
    "#Calculate find the nearest centroid for data point \n",
    "def MinDist(datapoint, centroid_points):\n",
    "    datapoint = array(datapoint)\n",
    "    centroid_points = array(centroid_points)\n",
    "    diff = datapoint - centroid_points \n",
    "    diffsq = diff**2\n",
    "    \n",
    "    distances = (diffsq.sum(axis = 1))**0.5\n",
    "    # Get the nearest centroid for each instance\n",
    "    min_idx = argmin(distances)\n",
    "    return min_idx\n",
    "\n",
    "#Check whether centroids converge\n",
    "def stop_criterion(centroid_points_old, centroid_points_new,T):\n",
    "    oldvalue = list(chain(*centroid_points_old))\n",
    "    newvalue = list(chain(*centroid_points_new))\n",
    "    Diff = [abs(x-y) for x, y in zip(oldvalue, newvalue)]\n",
    "    Flag = True\n",
    "    for i in Diff:\n",
    "        if(i>T):\n",
    "            Flag = False\n",
    "            break\n",
    "    return Flag\n",
    "\n",
    "\n",
    "class MRKmeans(MRJob):\n",
    "    centroid_points=[]\n",
    "    k=3    \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper_init = self.mapper_init, mapper=self.mapper,combiner = self.combiner,reducer=self.reducer)\n",
    "               ]\n",
    "    #load centroids info from file\n",
    "    def mapper_init(self):\n",
    "        self.centroid_points = [map(float,s.split('\\n')[0].split(',')) for s in open(\"Centroids.txt\").readlines()]\n",
    "        open('Centroids.txt', 'w').close()\n",
    "    #load data and output the nearest centroid index and data point \n",
    "    def mapper(self, _, line):\n",
    "        D = (map(float,line.split(',')))\n",
    "        idx = MinDist(D,self.centroid_points)\n",
    "        norm = math.sqrt(D[0]*D[0] + D[1]*D[1])\n",
    "        w = 1.0 / norm\n",
    "        #yield int(idx), (D[0],D[1],1)\n",
    "        yield int(idx), (D[0]*w,D[1]*w,w)\n",
    "    #Combine sum of data points locally\n",
    "    def combiner(self, idx, inputdata):\n",
    "        sumx = sumy = num = 0\n",
    "        for x,y,n in inputdata:\n",
    "            num = num + n\n",
    "            sumx = sumx + x\n",
    "            sumy = sumy + y\n",
    "        yield int(idx),(sumx,sumy,num)\n",
    "    #Aggregate sum for each cluster and then calculate the new centroids\n",
    "    def reducer(self, idx, inputdata): \n",
    "        centroids = []\n",
    "        num = [0]*self.k \n",
    "        distances = 0\n",
    "        for i in range(self.k):\n",
    "            centroids.append([0,0])\n",
    "        for x, y, n in inputdata:\n",
    "            num[idx] = num[idx] + n\n",
    "            centroids[idx][0] = centroids[idx][0] + x\n",
    "            centroids[idx][1] = centroids[idx][1] + y\n",
    "        centroids[idx][0] = centroids[idx][0]/num[idx]\n",
    "        centroids[idx][1] = centroids[idx][1]/num[idx]\n",
    "        with open('Centroids.txt', 'a') as f:\n",
    "            f.writelines(str(centroids[idx][0]) + ',' + str(centroids[idx][1]) + '\\n')\n",
    "        yield idx,(centroids[idx][0],centroids[idx][1])\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MRKmeans.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate random initial centroids\n",
    "\n",
    "New Centroids = initial centroids\n",
    "\n",
    "While(1)ï¼š\n",
    "+ Cacluate new centroids\n",
    "+ stop if new centroids close to old centroids\n",
    "+ Updates centroids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration1:\n",
      "0 [-2.6816121341554244, 0.4387800225117981]\n",
      "1 [5.203939274722273, 0.18108381085421293]\n",
      "2 [0.2798236662882328, 5.147133354098043]\n",
      "\n",
      "\n",
      "iteration2:\n",
      "0 [-4.499453073691768, 0.1017143951710932]\n",
      "1 [4.7342756092123475, -0.035081051175915486]\n",
      "2 [0.10883719601553689, 4.724161916864905]\n",
      "\n",
      "\n",
      "iteration3:\n",
      "0 [-4.618233072986696, 0.01209570625589213]\n",
      "1 [4.7342756092123475, -0.035081051175915486]\n",
      "2 [0.05163332299537063, 4.637075828035132]\n",
      "\n",
      "\n",
      "iteration4:\n",
      "0 [-4.618233072986696, 0.01209570625589213]\n",
      "1 [4.7342756092123475, -0.035081051175915486]\n",
      "2 [0.05163332299537063, 4.637075828035132]\n",
      "\n",
      "\n",
      "iteration5:\n",
      "0 [-4.618233072986696, 0.01209570625589213]\n",
      "1 [4.7342756092123475, -0.035081051175915486]\n",
      "2 [0.05163332299537063, 4.637075828035132]\n",
      "\n",
      "\n",
      "iteration6:\n",
      "0 [-4.618233072986696, 0.01209570625589213]\n",
      "1 [4.7342756092123475, -0.035081051175915486]\n",
      "2 [0.05163332299537063, 4.637075828035132]\n",
      "\n",
      "\n",
      "iteration7:\n",
      "0 [-4.618233072986696, 0.01209570625589213]\n",
      "1 [4.7342756092123475, -0.035081051175915486]\n",
      "2 [0.05163332299537063, 4.637075828035132]\n",
      "\n",
      "\n",
      "iteration8:\n",
      "0 [-4.618233072986696, 0.01209570625589213]\n",
      "1 [4.7342756092123475, -0.035081051175915486]\n",
      "2 [0.05163332299537063, 4.637075828035132]\n",
      "\n",
      "\n",
      "iteration9:\n",
      "0 [-4.618233072986696, 0.01209570625589213]\n",
      "1 [4.7342756092123475, -0.035081051175915486]\n",
      "2 [0.05163332299537063, 4.637075828035132]\n",
      "\n",
      "\n",
      "iteration10:\n",
      "0 [-4.618233072986696, 0.01209570625589213]\n",
      "1 [4.7342756092123475, -0.035081051175915486]\n",
      "2 [0.05163332299537063, 4.637075828035132]\n",
      "\n",
      "\n",
      "Centroids\n",
      "\n",
      "[[-4.618233072986696, 0.01209570625589213], [4.7342756092123475, -0.035081051175915486], [0.05163332299537063, 4.637075828035132]]\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from numpy import random, array\n",
    "from Kmeans import MRKmeans, stop_criterion\n",
    "mr_job = MRKmeans(args=['--file', 'Centroids.txt','Kmeandata.csv', '--no-strict-protocol'])\n",
    "\n",
    "#Geneate initial centroids\n",
    "centroid_points = [[0,0],[6,3],[3,6]]\n",
    "k = 3\n",
    "with open('Centroids.txt', 'w+') as f:\n",
    "        f.writelines(','.join(str(j) for j in i) + '\\n' for i in centroid_points)\n",
    "\n",
    "# Update centroids iteratively\n",
    "for i in range(10):\n",
    "    # save previous centoids to check convergency\n",
    "    centroid_points_old = centroid_points[:]\n",
    "    print \"iteration\"+str(i+1)+\":\"\n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        # stream_output: get access of the output \n",
    "        for line in runner.stream_output():\n",
    "            key,value =  mr_job.parse_output_line(line)\n",
    "            print key, value\n",
    "            centroid_points[key] = value\n",
    "    print \"\\n\"\n",
    "    i = i + 1\n",
    "print \"Centroids\\n\"\n",
    "print centroid_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 334.48027578170888, 1: 318.27727172885056, 2: 334.08381108198557}\n",
      "{0: 1001, 1: 998, 2: 1001}\n",
      "0 0.334146129652\n",
      "1 0.318915101933\n",
      "2 0.333750061021\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmin, array, random\n",
    "import math\n",
    "centroids = [[-4.618233072986696, 0.01209570625589213], \n",
    "             [4.7342756092123475, -0.035081051175915486], \n",
    "             [0.05163332299537063, 4.637075828035132]]\n",
    "\n",
    "def MinDist(datapoint, centroid_points):\n",
    "    datapoint = array(datapoint)\n",
    "    norm =  math.sqrt(sum(datapoint**2))\n",
    "    centroid_points = array(centroid_points)\n",
    "    diff = datapoint - centroid_points \n",
    "    diffsq = diff**2\n",
    "    \n",
    "    distances = (diffsq.sum(axis = 1))**0.5 / norm\n",
    "    # Get the nearest centroid for each instance\n",
    "    min_idx = argmin(distances)\n",
    "    return min_idx, distances[min_idx]\n",
    "\n",
    "count_dict = {}\n",
    "dist_dict = {}\n",
    "with open('Kmeandata.csv', 'r') as f:\n",
    "    for line in f:\n",
    "        D = (map(float,line.split(',')))\n",
    "        idx, d =  MinDist(D, centroids)\n",
    "        count_dict[idx] = count_dict.get(idx, 0) + 1\n",
    "        dist_dict[idx] = dist_dict.get(idx, 0) + d\n",
    "\n",
    "print dist_dict\n",
    "print count_dict\n",
    "\n",
    "for k,v in dist_dict.iteritems():\n",
    "    print k, v / count_dict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
